{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T02:32:57.800478Z",
     "start_time": "2018-10-24T02:32:47.356589Z"
    },
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import math\n",
    "import argparse\n",
    "import random\n",
    "import os\n",
    "from My_Loss import HardTripletLoss\n",
    "from My_Loss import HardTripletLoss2\n",
    "from My_Loss import HardTripletLoss_D\n",
    "from tensorboardX import SummaryWriter\n",
    "import visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T02:32:57.809773Z",
     "start_time": "2018-10-24T02:32:57.803644Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPISODE = 100000\n",
    "TEST_EPISODE = 1000\n",
    "LEARNING_RATE =1e-5\n",
    "Weight_Deacy = 0\n",
    "GPU = 0\n",
    "Margin = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T02:33:01.897672Z",
     "start_time": "2018-10-24T02:32:57.811791Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "print(\"init dataset\")\n",
    "##################################参数##################################################################\n",
    "dataroot = '../data'\n",
    "dataset = 'AwA1_data'\n",
    "image_embedding = 'res101'               #ResNet101层\n",
    "class_embedding = 'original_att'         #属性表达 85-d\n",
    "#######################################读取视觉特征###################################################################\n",
    "\n",
    "matcontent = sio.loadmat(dataroot + \"/\" + dataset + \"/\" + image_embedding + \".mat\")  #scipy loadmat\n",
    " \n",
    "feature = matcontent['features'].T         #转置 30478x2048 每一行是一个完整的样本\n",
    "\n",
    "label = matcontent['labels'].astype(int).squeeze() - 1   #matlab begin 1 ,numpy begin 0\n",
    "########################################读取属性特征###########################################################\n",
    "\n",
    "matcontent = sio.loadmat(dataroot + \"/\" + dataset + \"/\" + class_embedding + \"_splits.mat\")\n",
    "\n",
    "    \n",
    "# numpy array index starts from 0, matlab starts from 1\n",
    "trainval_loc = matcontent['trainval_loc'].squeeze() - 1    #squeeze()去掉维度中的1 AxBx1 --->AxB\n",
    "\n",
    "test_seen_loc = matcontent['test_seen_loc'].squeeze() - 1\n",
    "test_unseen_loc = matcontent['test_unseen_loc'].squeeze() - 1\n",
    "\n",
    "attribute = matcontent['att'].T    #转置 50x85 每行是整个属性向量\n",
    "\n",
    "x = feature[trainval_loc]                      # train_features trainval里面是图片的编号 begin with 0 ，19832个\n",
    "train_label = label[trainval_loc].astype(int)  # train_label  int类型没变 每个图片的lable 19832个\n",
    "train_id = np.unique(train_label)\n",
    "\n",
    "att = attribute[train_label]                   # train attributes 每个图片的属性 19832个\n",
    "\n",
    "    \n",
    "x_test = feature[test_unseen_loc]                   # test_feature 5685个\n",
    "test_label = label[test_unseen_loc].astype(int)     # test_label   5685个\n",
    "\n",
    "x_test_seen = feature[test_seen_loc]                #test_seen_feature 4958个\n",
    "test_label_seen = label[test_seen_loc].astype(int)  # test_seen_label  4958个\n",
    "    \n",
    "test_id = np.unique(test_label)                     # test_id  10个类 ，unique去重\n",
    "att_pro = attribute[test_id]                        # test_attribute 每一类的属性向量 10x85\n",
    "\n",
    "# train set\n",
    "train_features = torch.from_numpy(x)   #np-->tensor\n",
    "#train_fearures_negative = torch.from_numpy(x_negative)\n",
    "\n",
    "sample_attributes=[]\n",
    "train_label = torch.from_numpy(train_label).unsqueeze(1) #每张图片的属性转化 ，unsqueeze(1)就是插入到第一维度 AxB维-->Ax1xB\n",
    "# attributes\n",
    "all_attributes = np.array(attribute)  #所有50类属性转变为numpy数组???属性向量仍然用的numpy类型 没有转化为pytorch\n",
    "    \n",
    "#print('-'*50)\n",
    "attributes = torch.from_numpy(attribute) \n",
    "#print(attribute)\n",
    "# test set\n",
    "\n",
    "test_features = torch.from_numpy(x_test)\n",
    "#print(test_features.shape)\n",
    "\n",
    "test_label = torch.from_numpy(test_label).unsqueeze(1)\n",
    "#print(test_label.shape)\n",
    "\n",
    "testclasses_id = np.array(test_id)\n",
    "#print(testclasses_id.shape)\n",
    "\n",
    "test_attributes = torch.from_numpy(att_pro).float()\n",
    "#print(test_attributes.shape)\n",
    "\n",
    "test_seen_features = torch.from_numpy(x_test_seen)\n",
    "#print(test_seen_features.shape)\n",
    "\n",
    "test_seen_label = torch.from_numpy(test_label_seen)\n",
    "\n",
    "train_data = TensorDataset( train_label, train_features )\n",
    "#train_data = TensorDataset(train_label, train_features, train_fearures_negative)\n",
    "\n",
    "#################here need new code to make triplet data#####################\n",
    "print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T02:33:01.918599Z",
     "start_time": "2018-10-24T02:33:01.899074Z"
    },
    "collapsed": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from my_net_3 import AttributeNetwork\n",
    "from my_net_3 import MetricNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T02:33:11.775577Z",
     "start_time": "2018-10-24T02:33:01.920004Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# init network\n",
    "print(\"init networks\")\n",
    "attribute_network = AttributeNetwork(85,1024,2048)  #85d属性 1024隐藏层 2048输出 85d到2048d\n",
    "metric_network = MetricNetwork(2048,1024,2048)\n",
    "\n",
    "attribute_network.cuda(GPU) \n",
    "metric_network.cuda(GPU)\n",
    "\n",
    "#学习率每200k步 乘0.5\n",
    "attribute_network_optim = torch.optim.Adam(attribute_network.parameters(), lr=LEARNING_RATE,weight_decay=Weight_Deacy)\n",
    "metric_network_optim = torch.optim.Adam(metric_network.parameters(), lr=LEARNING_RATE,weight_decay=Weight_Deacy)\n",
    "#\n",
    "#triplet_network_optim = torch.optim.SGD(triplet_network.parameters(), lr=LEARNING_RATE,momentum=0.9 , \n",
    "#                                         weight_decay=Weight_Deacy)\n",
    "\n",
    "attribute_network_scheduler = StepLR(attribute_network_optim , step_size=20000 , gamma=0.5)\n",
    "metric_network_scheduler = StepLR(metric_network_optim , step_size=20000 , gamma=0.5)\n",
    "#\n",
    "print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T02:33:11.787457Z",
     "start_time": "2018-10-24T02:33:11.777763Z"
    },
    "collapsed": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(test_features, test_label, test_id, test_attributes):\n",
    "    \n",
    "    test_data = TensorDataset(test_features, test_label)\n",
    "    test_batch = 32\n",
    "    test_loader = DataLoader(test_data, batch_size=test_batch, shuffle=False)\n",
    "    total_rewards = 0\n",
    "\n",
    "    sample_labels = test_id\n",
    "    sample_attributes = test_attributes\n",
    "    class_num = sample_attributes.shape[0]\n",
    "    test_size = test_features.shape[0]\n",
    "\n",
    "    print(\"class num:\", class_num)\n",
    "\n",
    "    for batch_features,batch_labels in test_loader:\n",
    "\n",
    "        batch_size = batch_labels.shape[0]\n",
    "        batch_features_ext = torch.from_numpy(batch_features.numpy().repeat(class_num, 0))\n",
    "        batch_features_ext = metric_network(Variable(batch_features_ext).cuda(GPU).float())  # 32*1024\n",
    "\n",
    "\n",
    "        sample_features = metric_network(attribute_network(Variable(sample_attributes).cuda(GPU).float()))\n",
    "        sample_features_ext = sample_features.repeat(batch_size, 1)\n",
    "\n",
    "\n",
    "        relations = F.pairwise_distance(batch_features_ext, sample_features_ext, 2).view(-1, class_num)\n",
    "        re_batch_labels = []\n",
    "        for label in batch_labels.numpy():\n",
    "            index = np.argwhere(sample_labels == label)\n",
    "            re_batch_labels.append(index[0][0])\n",
    "        re_batch_labels = torch.cuda.LongTensor(re_batch_labels)\n",
    "\n",
    "\n",
    "        _, predict_labels = torch.min(relations.data, 1)\n",
    "        rewards = [1 if predict_labels[j] == re_batch_labels[j] else 0 for j in range(batch_size)]\n",
    "        total_rewards += np.sum(rewards)\n",
    "    test_accuracy = total_rewards/1.0/test_size\n",
    "    return  test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T02:33:11.801606Z",
     "start_time": "2018-10-24T02:33:11.790893Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_accuracy_per_class(test_features, test_label, test_id, test_attributes):\n",
    "    \n",
    "    test_data = TensorDataset(test_features, test_label)\n",
    "    test_batch = 32\n",
    "    test_loader = DataLoader(test_data, batch_size=test_batch, shuffle=False)\n",
    "    total_rewards = 0\n",
    "    #print(test_features.size())\n",
    "    sample_labels = test_id\n",
    "    sample_attributes = test_attributes\n",
    "    class_num = sample_attributes.shape[0]\n",
    "    test_size = test_features.shape[0]\n",
    "    per_class_num = np.zeros(class_num)\n",
    "    per_class_true= np.zeros(class_num)\n",
    "\n",
    "    print(\"class num:\", class_num)\n",
    "\n",
    "    for batch_features,batch_labels in test_loader:\n",
    "\n",
    "        batch_size = batch_labels.shape[0]\n",
    "        batch_features_ext = torch.from_numpy(batch_features.numpy().repeat(class_num, 0))\n",
    "        batch_features_ext = metric_network(Variable(batch_features_ext).cuda(GPU).float())  # 32*1024\n",
    "\n",
    "\n",
    "        sample_features = metric_network(attribute_network(Variable(sample_attributes).cuda(GPU).float()))\n",
    "        sample_features_ext = sample_features.repeat(batch_size, 1)\n",
    "\n",
    "\n",
    "        relations = F.pairwise_distance(batch_features_ext, sample_features_ext, 2).view(-1, class_num)\n",
    "        re_batch_labels = []\n",
    "        for label in batch_labels.numpy():\n",
    "            index = np.argwhere(sample_labels == label)\n",
    "            re_batch_labels.append(index[0][0])\n",
    "        re_batch_labels_id, batch_per_num = np.unique(re_batch_labels , return_counts=True) \n",
    "        re_batch_labels = torch.cuda.LongTensor(re_batch_labels)\n",
    "        \n",
    "        for each in range(re_batch_labels_id.size):\n",
    "            #print(re_batch_labels_id[each])\n",
    "            #print(batch_per_num[each])\n",
    "            per_class_num[re_batch_labels_id[each]] = per_class_num[re_batch_labels_id[each]] + batch_per_num[each]\n",
    "        #print(re_batch_labels_id)\n",
    "        #print('-'*100)\n",
    "        #print(batch_per_num)\n",
    "        #print('-'*100)\n",
    "\n",
    "\n",
    "        _, predict_labels = torch.min(relations.data, 1)\n",
    "        for j in range(batch_size):\n",
    "            if predict_labels[j] == re_batch_labels[j]:\n",
    "                per_class_true[re_batch_labels[j]] = per_class_true[re_batch_labels[j]] + 1\n",
    "            \n",
    "    per_accuracy = per_class_true[np.nonzero(per_class_num)] / per_class_num[np.nonzero(per_class_num)]\n",
    "    \n",
    "\n",
    "    test_accuracy = np.sum(per_accuracy)/1.0/np.count_nonzero(per_class_num)\n",
    "   \n",
    "    #print(np.count_nonzero(per_class_num))\n",
    "    return  test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T09:26:13.190819Z",
     "start_time": "2018-10-24T09:24:04.981346Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"training...\")\n",
    "last_accuracy = 0.0\n",
    "loss_zero_num =0\n",
    "writer = SummaryWriter()\n",
    "#vis = visdom.Visdom()\n",
    "for episode in range(EPISODE):\n",
    "\n",
    "    attribute_network_scheduler.step(episode)\n",
    "    metric_network_scheduler.step(episode)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    batch_labels, batch_features = train_loader.__iter__().next()\n",
    "    batch_id = np.unique(batch_labels)\n",
    "\n",
    "    batch_attributes = torch.Tensor([all_attributes[i] for i in batch_id]).squeeze(1)\n",
    "    batch_features_ext = torch.from_numpy(batch_features.numpy().repeat(batch_id.size, 0))\n",
    "    batch_attributes_ext = batch_attributes.repeat(BATCH_SIZE, 1)\n",
    "\n",
    "    batch_features_ext = Variable(batch_features_ext).cuda(GPU).float()  # 32*2048\n",
    "    batch_attributes_ext = Variable(batch_attributes_ext).cuda(GPU)\n",
    "\n",
    "\n",
    "    re_batch_labels = []\n",
    "    for label in batch_labels.numpy():\n",
    "        index = np.argwhere(batch_id == label)\n",
    "        re_batch_labels.append(index[0][0])\n",
    "    re_batch_labels = torch.cuda.LongTensor(re_batch_labels)\n",
    "    re_batch_labels = Variable(re_batch_labels).cuda(GPU)\n",
    "    \n",
    "\n",
    "    criterion = HardTripletLoss_D(margin = Margin).cuda(GPU)\n",
    "    triplet_loss= criterion(metric_network(attribute_network(batch_attributes_ext)), \n",
    "                            metric_network(batch_features_ext), re_batch_labels)\n",
    "    if triplet_loss == 0:\n",
    "        loss_zero_num = loss_zero_num + 1\n",
    "    \n",
    "    \n",
    "    attribute_network.zero_grad()\n",
    "    metric_network.zero_grad()\n",
    "    \n",
    "    triplet_loss.backward()\n",
    "    \n",
    "    attribute_network_optim.step()\n",
    "    metric_network_optim.step()\n",
    "\n",
    "    \n",
    "    if (episode+1)%200 == 0 or episode==0:\n",
    "        print(\"episode:\", episode+1, \"loss\", triplet_loss)\n",
    "        print('loss_zero_number= ',loss_zero_num)\n",
    "        loss_zero_num = 0\n",
    "        writer.add_scalar('data/loss', triplet_loss, episode)\n",
    "    \n",
    "    if (episode+1)%200 == 0 or episode==0:\n",
    "        print(\"Testing...\")\n",
    "        #attribute_network.eval()\n",
    "        zsl_accuracy = compute_accuracy_per_class(test_features, test_label, test_id, test_attributes)\n",
    "        gzsl_unseen_accuracy = compute_accuracy_per_class(test_features, test_label, np.arange(50), attributes)\n",
    "        gzsl_seen_accuracy = compute_accuracy_per_class(test_seen_features, test_seen_label, np.arange(50), attributes)\n",
    "        H = 2 * gzsl_seen_accuracy * gzsl_unseen_accuracy / (gzsl_unseen_accuracy + gzsl_seen_accuracy)\n",
    "        #H2 = 2 * gzsl_seen_accuracy2 * gzsl_unseen_accuracy2 / (gzsl_unseen_accuracy2 + gzsl_seen_accuracy2)\n",
    "        print('zsl:', zsl_accuracy)\n",
    "        #print('zsl:', zsl_accuracy2)\n",
    "        print('gzsl: unseen=%.4f , seen=%.4f , h=%.4f' % (gzsl_unseen_accuracy , gzsl_seen_accuracy, H))\n",
    "        #print('gzsl: unseen=%.4f , seen=%.4f , h=%.4f' % (gzsl_unseen_accuracy2 , gzsl_seen_accuracy2, H2))\n",
    "        print('_'*100)\n",
    "        writer.add_scalar('data/zsl_accuracy', zsl_accuracy, episode)\n",
    "        writer.add_scalar('data/gzsl_unseen_accuracy', gzsl_unseen_accuracy, episode)\n",
    "        writer.add_scalar('data/gzsl_seen_accuracy', gzsl_seen_accuracy, episode)\n",
    "        writer.add_scalar('data/H', H, episode)\n",
    "#features = images.view(, 784)\n",
    "#print(vis_label.size())\n",
    "#writer.add_embedding(vis_images, metadata = vis_label.tolist())\n",
    "#writer.add_embedding(vis_att, metadata = vis_label_att)\n",
    "#writer.export_scalars_to_json(\"./test.json\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
